{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evh4OQXjEbIh",
        "outputId": "76c6c304-4283-413a-da1e-7564adb35451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import (Concatenate, Conv2D, Dense, Dropout,\n",
        "                                     Flatten, GlobalAveragePooling2D, Input,\n",
        "                                     MaxPooling2D)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm.keras import TqdmCallback\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n"
      ],
      "metadata": {
        "id": "BIMKJrl_F_Jo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the data\n",
        "\n",
        "x = np.load('/content/drive/My Drive/data/x_std.npy')\n",
        "y = np.load('/content/drive/My Drive/data/y.npy')\n",
        "\n",
        "x_rgb = x[:,:,:, [3, 2, 1]].copy()\n",
        "x_additional = np.delete(x, [3, 2, 1], axis=3)  # assuming the additional bands are at these indices\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "x_train_rgb, x_test_rgb, y_train, y_test = train_test_split(x_rgb, y, test_size=0.2, random_state=42)\n",
        "x_train_additional, x_test_additional = train_test_split(x_additional, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a custom input layer for the RGB input\n",
        "input_layer_rgb = Input(shape=(64, 64, 3))\n",
        "resizing_layer_rgb = Resizing(224, 224, interpolation=\"Bilinear\")(input_layer_rgb)\n",
        "base_model_rgb = ResNet50(weights='imagenet', include_top=False, input_tensor=resizing_layer_rgb)\n",
        "\n",
        "# Create a custom input layer for the additional bands\n",
        "input_layer_additional = Input(shape=(64, 64, x_additional.shape[3]))\n",
        "base_model_additional = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer_additional)\n",
        "\n",
        "# Extract features from the RGB and additional bands\n",
        "features_rgb = GlobalAveragePooling2D()(base_model_rgb.output)\n",
        "features_additional = GlobalAveragePooling2D()(base_model_additional.output)\n",
        "\n",
        "# Combine the features and add a classification layer\n",
        "combined_features = tf.keras.layers.concatenate([features_rgb, features_additional])\n",
        "x = Dense(1024, activation='relu')(combined_features)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(y.shape[1], activation='softmax')(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "zpRewC6WLgwR",
        "outputId": "6fcc7005-24a2-4d1b-b6f0-afce208014b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9ce556287c04>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and preprocess the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/data/x_std.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/data/y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers in the base models\n",
        "for layer in base_model_rgb.layers:\n",
        "    layer.trainable = False\n",
        "for layer in base_model_additional.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Unfreeze the last two residual blocks (9 layers)\n",
        "for layer in base_model_rgb.layers[-9:]:\n",
        "    layer.trainable = True\n",
        "for layer in base_model_additional.layers[-9:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=[input_layer_rgb, input_layer_additional], outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.003), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    shear_range=0.2,  # added shear transformation\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        "    # vertical_flip=True,\n",
        "    # zoom_range=0.2,Â  # added zoom\n",
        ")\n"
      ],
      "metadata": {
        "id": "yoA2nMpWLmpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20Gp25hOJUmZ"
      },
      "outputs": [],
      "source": [
        "# Define the early stopping callback\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"resnet50_std_wo_deeper_batch_128.h5\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\", mode=\"max\", patience=5, verbose=1, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Fit the model with the augmented data\n",
        "batch_size = 50\n",
        "epochs = 20\n",
        "model.fit([datagen.flow(x_train_rgb, y_train, batch_size=batch_size), x_train_additional],\n",
        "          steps_per_epoch=len(x_train_rgb) // batch_size,\n",
        "          validation_data=([x_test_rgb, x_test_additional], y_test),\n",
        "          epochs=epochs,\n",
        "          # callbacks=[checkpoint_callback, early_stopping_callback])  \n",
        "          callbacks=[TqdmCallback(verbose=1), checkpoint_callback, early_stopping_callback])\n"
      ]
    }
  ]
}